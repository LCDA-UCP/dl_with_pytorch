{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# IMDB 50K Movie Reviews - Sentiment Classification with MLP\n",
    "\n",
    "## Overview\n",
    "\n",
    "### In the next exercises, you will work with the IMDB 50K Movie Reviews dataset to build a sentiment analysis model using a Multi-Layer Perceptron (MLP). You will practice essential steps in the data science pipeline such as data loading, preprocessing, feature generation, and training/testing a neural network model. This exercise should be completed using the `pandas`, `nltk`, `sklearn`, and `torch` libraries.\n"
   ],
   "id": "fbc88e3cb2c788d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 1: Data Loading and Exploration\n",
    "**Objective**: Load the IMDB dataset and explore its structure.\n",
    "\n",
    "1. **Load the dataset** using `pandas`. The dataset is in the `data/` folder and the file name is `imdb_dataset.zip`. **Hint: you can load zip files with pandas by passing `compression='zip'` tp `pd.read_csv`**\n",
    "2. **Explore the dataset** by checking for missing values and getting a summary of the data. \n",
    "    - Check the shape of the dataset.\n",
    "    - Get the distribution of the sentiment labels (positive/negative reviews).\n",
    "3. Print the first few reviews and their corresponding labels.\n"
   ],
   "id": "1967f805bf9ca917"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:14.507062Z",
     "start_time": "2024-10-04T09:13:10.750313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import modin.pandas as pd # Optimized distributed version of Pandas\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../../data/imdb_dataset.zip', compression='zip')  # Load as per your format\n",
    "df.head()"
   ],
   "id": "a53cce52163c4447",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:13:12,351\tINFO worker.py:1786 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:14.611531Z",
     "start_time": "2024-10-04T09:13:14.548827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ],
   "id": "e57bb2bb70f9f4ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:14.756225Z",
     "start_time": "2024-10-04T09:13:14.658701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the distribution of labels\n",
    "df['sentiment'].value_counts()"
   ],
   "id": "6388a96dd14227db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `df.groupby(categorical_by, sort=False)` implementation has mismatches with pandas:\n",
      "the groupby keys will be sorted anyway, although the 'sort=False' was passed. See the following issue for more details: https://github.com/modin-project/modin/issues/3571.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    25000\n",
       "positive    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 2: Splitting the Data\n",
    "**Objective**: Split the data into training, validation and test sets.\n",
    "\n",
    "1. Split the dataset into features (reviews) and labels (sentiment).\n",
    "2. Use `train_test_split` from `sklearn` to split the dataset into training, validation and test sets (use an 60/20/20 split).\n",
    "3. Print the sizes of the training, validation and test sets to ensure the splits were done correctly."
   ],
   "id": "d50a1d1bcc857961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:15.567137Z",
     "start_time": "2024-10-04T09:13:15.316859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into features (X) and labels (y)\n",
    "X = df['review']\n",
    "y = df['sentiment']"
   ],
   "id": "1cd385320714117c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:15.816641Z",
     "start_time": "2024-10-04T09:13:15.719576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split into training (60%), validation (20%), and test (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ],
   "id": "7543576eeb9d21ff",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:15.826650Z",
     "start_time": "2024-10-04T09:13:15.824031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ],
   "id": "cb278e805672ee97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 30000\n",
      "Validation set size: 10000\n",
      "Test set size: 10000\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 3: Text Preprocessing\n",
    "**Objective**: Preprocess the text data to prepare it for feature generation.\n",
    "\n",
    "1. Lowercase the text data. **Hint: python has a built-in string method for this**.\n",
    "2. Remove any URL from the reviews. **Hint: you can use regular expressions for this**.\n",
    "3. Remove non-word and non-whitespace characters (punctuation, special characters, etc.). **Hint: you can use regular expressions for this**.\n",
    "4. Remove digits. **Hint: you can use regular expressions for this**.\n",
    "5. Tokenize the reviews into individual words. **Hint: you can use the `nltk` library for this**.\n",
    "6. Remove stopwords. **Hint: you can use the `nltk` library for this**.\n",
    "7. Perform stemming or lemmatization. **Hint: you can use the `nltk` library for this**.\n",
    "8. Apply the preprocessing steps to both the training, validation and test sets."
   ],
   "id": "2565a8072f03328a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:45.037575Z",
     "start_time": "2024-10-04T09:13:44.509961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ],
   "id": "274001c7274aa06d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/lcda/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/lcda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:47.586668Z",
     "start_time": "2024-10-04T09:13:47.582660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word/non-whitespace characters\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    words = word_tokenize(text)  # Tokenize text\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stop words\n",
    "    words = [stemmer.stem(word) for word in words]  # Perform stemming\n",
    "    return ' '.join(words)"
   ],
   "id": "20728d8e4d17ae5f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:50.033976Z",
     "start_time": "2024-10-04T09:13:49.875461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply preprocessing to the training, validation, and test sets\n",
    "X_train = X_train.apply(preprocess_text)\n",
    "X_val = X_val.apply(preprocess_text)\n",
    "X_test = X_test.apply(preprocess_text)"
   ],
   "id": "838d9aed37b5086b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T09:13:51.817153Z",
     "start_time": "2024-10-04T09:13:51.729529Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.head()",
   "id": "198fe3ef1a4716f6",
   "outputs": [
    {
     "ename": "RayTaskError(LookupError)",
     "evalue": "\u001B[36mray::remote_exec_func()\u001B[39m (pid=23047, ip=192.168.126.137)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001B[36mray::remote_exec_func()\u001B[39m (pid=23057, ip=192.168.126.137)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001B[36mray::remote_exec_func()\u001B[39m (pid=23032, ip=192.168.126.137)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/execution/ray/common/deferred_execution.py\", line 810, in remote_exec_func\n    obj = remote_executor.exec_func(fn, obj, flat_args, flat_kwargs)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/execution/ray/common/deferred_execution.py\", line 605, in exec_func\n    raise err\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/execution/ray/common/deferred_execution.py\", line 592, in exec_func\n    return fn(obj, *args, **kwargs)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/dataframe/algebra/map.py\", line 51, in <lambda>\n    lambda x: function(x, *args, **kwargs), *call_args, **call_kwds\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/frame.py\", line 10468, in map\n    return self.apply(infer).__finalize__(self, \"map\")\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/frame.py\", line 10374, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/apply.py\", line 916, in apply\n    return self.apply_standard()\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/apply.py\", line 1063, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/apply.py\", line 1081, in apply_series_generator\n    results[i] = self.func(v, *self.args, **self.kwargs)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/frame.py\", line 10466, in infer\n    return x._map_values(func, na_action=na_action)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/base.py\", line 921, in _map_values\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/algorithms.py\", line 1743, in map_array\n    return lib.map_infer(values, mapper, convert=convert)\n  File \"lib.pyx\", line 2972, in pandas._libs.lib.map_infer\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/pandas/series.py\", line 1268, in <lambda>\n    arg(s) if pandas.isnull(s) is not True or na_action is None else s\n  File \"/tmp/ipykernel_22696/2397226419.py\", line 7, in preprocess_text\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/__init__.py\", line 142, in word_tokenize\n    sentences = [text] if preserve_line else sent_tokenize(text, language)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/__init__.py\", line 119, in sent_tokenize\n    tokenizer = _get_punkt_tokenizer(language)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/__init__.py\", line 105, in _get_punkt_tokenizer\n    return PunktTokenizer(language)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/punkt.py\", line 1744, in __init__\n    self.load_lang(lang)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/punkt.py\", line 1749, in load_lang\n    lang_dir = find(f\"tokenizers/punkt_tab/{lang}/\")\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/data.py\", line 579, in find\n    raise LookupError(resource_not_found)\nLookupError: \n**********************************************************************\n  Resource \u001B[93mpunkt_tab\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt_tab/english/\u001B[0m\n\n  Searched in:\n    - '/home/lcda/nltk_data'\n    - '/home/lcda/miniconda3/envs/dl_with_pytorch/nltk_data'\n    - '/home/lcda/miniconda3/envs/dl_with_pytorch/share/nltk_data'\n    - '/home/lcda/miniconda3/envs/dl_with_pytorch/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRayTaskError(LookupError)\u001B[0m                 Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/IPython/core/formatters.py:711\u001B[0m, in \u001B[0;36mPlainTextFormatter.__call__\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    704\u001B[0m stream \u001B[38;5;241m=\u001B[39m StringIO()\n\u001B[1;32m    705\u001B[0m printer \u001B[38;5;241m=\u001B[39m pretty\u001B[38;5;241m.\u001B[39mRepresentationPrinter(stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_width, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnewline,\n\u001B[1;32m    707\u001B[0m     max_seq_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_seq_length,\n\u001B[1;32m    708\u001B[0m     singleton_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msingleton_printers,\n\u001B[1;32m    709\u001B[0m     type_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtype_printers,\n\u001B[1;32m    710\u001B[0m     deferred_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeferred_printers)\n\u001B[0;32m--> 711\u001B[0m \u001B[43mprinter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpretty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    712\u001B[0m printer\u001B[38;5;241m.\u001B[39mflush()\n\u001B[1;32m    713\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stream\u001B[38;5;241m.\u001B[39mgetvalue()\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/IPython/lib/pretty.py:419\u001B[0m, in \u001B[0;36mRepresentationPrinter.pretty\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    408\u001B[0m                         \u001B[38;5;28;01mreturn\u001B[39;00m meth(obj, \u001B[38;5;28mself\u001B[39m, cycle)\n\u001B[1;32m    409\u001B[0m                 \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    410\u001B[0m                     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mobject\u001B[39m\n\u001B[1;32m    411\u001B[0m                     \u001B[38;5;66;03m# check if cls defines __repr__\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    417\u001B[0m                     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(_safe_getattr(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__repr__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    418\u001B[0m                 ):\n\u001B[0;32m--> 419\u001B[0m                     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_repr_pprint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcycle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _default_pprint(obj, \u001B[38;5;28mself\u001B[39m, cycle)\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/IPython/lib/pretty.py:787\u001B[0m, in \u001B[0;36m_repr_pprint\u001B[0;34m(obj, p, cycle)\u001B[0m\n\u001B[1;32m    785\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001B[39;00m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;66;03m# Find newlines and replace them with p.break_()\u001B[39;00m\n\u001B[0;32m--> 787\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mrepr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    788\u001B[0m lines \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39msplitlines()\n\u001B[1;32m    789\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m p\u001B[38;5;241m.\u001B[39mgroup():\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/logging/logger_decorator.py:125\u001B[0m, in \u001B[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03mAny\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m LogMode\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m logger \u001B[38;5;241m=\u001B[39m get_logger()\n\u001B[1;32m    128\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(log_level, start_line)\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/pandas/series.py:404\u001B[0m, in \u001B[0;36mSeries.__repr__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    402\u001B[0m num_rows \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mget_option(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisplay.max_rows\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m60\u001B[39m\n\u001B[1;32m    403\u001B[0m num_cols \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mget_option(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisplay.max_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m20\u001B[39m\n\u001B[0;32m--> 404\u001B[0m temp_df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_repr_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_cols\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(temp_df, pandas\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m temp_df\u001B[38;5;241m.\u001B[39mempty:\n\u001B[1;32m    406\u001B[0m     temp_df \u001B[38;5;241m=\u001B[39m temp_df\u001B[38;5;241m.\u001B[39miloc[:, \u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/logging/logger_decorator.py:125\u001B[0m, in \u001B[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03mAny\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m LogMode\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m logger \u001B[38;5;241m=\u001B[39m get_logger()\n\u001B[1;32m    128\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(log_level, start_line)\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/pandas/base.py:262\u001B[0m, in \u001B[0;36mBasePandasDataset._build_repr_df\u001B[0;34m(self, num_rows, num_cols)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    261\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m row_indexer\n\u001B[0;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_query_compiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_pandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/logging/logger_decorator.py:125\u001B[0m, in \u001B[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03mAny\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m LogMode\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m logger \u001B[38;5;241m=\u001B[39m get_logger()\n\u001B[1;32m    128\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(log_level, start_line)\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler.py:293\u001B[0m, in \u001B[0;36mPandasQueryCompiler.to_pandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_pandas\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_modin_frame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_pandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/logging/logger_decorator.py:125\u001B[0m, in \u001B[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03mAny\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m LogMode\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m logger \u001B[38;5;241m=\u001B[39m get_logger()\n\u001B[1;32m    128\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(log_level, start_line)\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/utils.py:503\u001B[0m, in \u001B[0;36mlazy_metadata_decorator.<locals>.decorator.<locals>.run_f_on_minimally_updated_metadata\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    501\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m apply_axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrows\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    502\u001B[0m         obj\u001B[38;5;241m.\u001B[39m_propagate_index_objs(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 503\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m apply_axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m transpose:\n\u001B[1;32m    505\u001B[0m     result\u001B[38;5;241m.\u001B[39m_deferred_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deferred_index\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:4465\u001B[0m, in \u001B[0;36mPandasDataframe.to_pandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   4456\u001B[0m \u001B[38;5;129m@lazy_metadata_decorator\u001B[39m(apply_axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   4457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_pandas\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   4458\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4459\u001B[0m \u001B[38;5;124;03m    Convert this Modin DataFrame to a pandas DataFrame.\u001B[39;00m\n\u001B[1;32m   4460\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4463\u001B[0m \u001B[38;5;124;03m    pandas.DataFrame\u001B[39;00m\n\u001B[1;32m   4464\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4465\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_partition_mgr_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_pandas\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_partitions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4466\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m df\u001B[38;5;241m.\u001B[39mempty:\n\u001B[1;32m   4467\u001B[0m         df \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDataFrame(columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/logging/logger_decorator.py:125\u001B[0m, in \u001B[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03mAny\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m LogMode\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m logger \u001B[38;5;241m=\u001B[39m get_logger()\n\u001B[1;32m    128\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(log_level, start_line)\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:801\u001B[0m, in \u001B[0;36mPandasDataframePartitionManager.to_pandas\u001B[0;34m(cls, partitions)\u001B[0m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    787\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_pandas\u001B[39m(\u001B[38;5;28mcls\u001B[39m, partitions):\n\u001B[1;32m    788\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;124;03m    Convert NumPy array of PandasDataframePartition to pandas DataFrame.\u001B[39;00m\n\u001B[1;32m    790\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    799\u001B[0m \u001B[38;5;124;03m        A pandas DataFrame\u001B[39;00m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 801\u001B[0m     retrieved_objects \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_objects_from_partitions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpartitions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m create_pandas_df_from_partitions(retrieved_objects, partitions\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/logging/logger_decorator.py:125\u001B[0m, in \u001B[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03mAny\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m LogMode\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m logger \u001B[38;5;241m=\u001B[39m get_logger()\n\u001B[1;32m    128\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(log_level, start_line)\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:986\u001B[0m, in \u001B[0;36mPandasDataframePartitionManager.get_objects_from_partitions\u001B[0;34m(cls, partitions)\u001B[0m\n\u001B[1;32m    982\u001B[0m             partitions[idx] \u001B[38;5;241m=\u001B[39m part\u001B[38;5;241m.\u001B[39mforce_materialization()\n\u001B[1;32m    983\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\n\u001B[1;32m    984\u001B[0m         [\u001B[38;5;28mlen\u001B[39m(partition\u001B[38;5;241m.\u001B[39mlist_of_blocks) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m partition \u001B[38;5;129;01min\u001B[39;00m partitions]\n\u001B[1;32m    985\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImplementation assumes that each partition contains a single block.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 986\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_wrapper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaterialize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    987\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43mpartition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_of_blocks\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpartition\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpartitions\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    988\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [partition\u001B[38;5;241m.\u001B[39mget() \u001B[38;5;28;01mfor\u001B[39;00m partition \u001B[38;5;129;01min\u001B[39;00m partitions]\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/execution/ray/common/engine_wrapper.py:129\u001B[0m, in \u001B[0;36mRayWrapper.materialize\u001B[0;34m(cls, obj_id)\u001B[0m\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ray\u001B[38;5;241m.\u001B[39mget(obj_id) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj_id, RayObjectRefTypes) \u001B[38;5;28;01melse\u001B[39;00m obj_id\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(obj, RayObjectRefTypes) \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m obj_id):\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m ids \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    132\u001B[0m result \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:21\u001B[0m, in \u001B[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mauto_init_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     20\u001B[0m     auto_init_ray()\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001B[0m, in \u001B[0;36mclient_mode_hook.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m is_client_mode_enabled_by_default:\n\u001B[1;32m    102\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(ray, func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/ray/_private/worker.py:2691\u001B[0m, in \u001B[0;36mget\u001B[0;34m(object_refs, timeout)\u001B[0m\n\u001B[1;32m   2685\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2686\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid type of object refs, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(object_refs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, is given. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2687\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject_refs\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must either be an ObjectRef or a list of ObjectRefs. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2688\u001B[0m     )\n\u001B[1;32m   2690\u001B[0m \u001B[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001B[39;00m\n\u001B[0;32m-> 2691\u001B[0m values, debugger_breakpoint \u001B[38;5;241m=\u001B[39m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobject_refs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2692\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(values):\n\u001B[1;32m   2693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, RayError):\n",
      "File \u001B[0;32m~/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/ray/_private/worker.py:871\u001B[0m, in \u001B[0;36mWorker.get_objects\u001B[0;34m(self, object_refs, timeout, return_exceptions)\u001B[0m\n\u001B[1;32m    869\u001B[0m     global_worker\u001B[38;5;241m.\u001B[39mcore_worker\u001B[38;5;241m.\u001B[39mdump_object_store_memory_usage()\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, RayTaskError):\n\u001B[0;32m--> 871\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mas_instanceof_cause()\n\u001B[1;32m    872\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\n",
      "\u001B[0;31mRayTaskError(LookupError)\u001B[0m: \u001B[36mray::remote_exec_func()\u001B[39m (pid=23047, ip=192.168.126.137)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001B[36mray::remote_exec_func()\u001B[39m (pid=23057, ip=192.168.126.137)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001B[36mray::remote_exec_func()\u001B[39m (pid=23032, ip=192.168.126.137)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/execution/ray/common/deferred_execution.py\", line 810, in remote_exec_func\n    obj = remote_executor.exec_func(fn, obj, flat_args, flat_kwargs)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/execution/ray/common/deferred_execution.py\", line 605, in exec_func\n    raise err\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/execution/ray/common/deferred_execution.py\", line 592, in exec_func\n    return fn(obj, *args, **kwargs)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/core/dataframe/algebra/map.py\", line 51, in <lambda>\n    lambda x: function(x, *args, **kwargs), *call_args, **call_kwds\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/frame.py\", line 10468, in map\n    return self.apply(infer).__finalize__(self, \"map\")\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/frame.py\", line 10374, in apply\n    return op.apply().__finalize__(self, method=\"apply\")\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/apply.py\", line 916, in apply\n    return self.apply_standard()\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/apply.py\", line 1063, in apply_standard\n    results, res_index = self.apply_series_generator()\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/apply.py\", line 1081, in apply_series_generator\n    results[i] = self.func(v, *self.args, **self.kwargs)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/frame.py\", line 10466, in infer\n    return x._map_values(func, na_action=na_action)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/base.py\", line 921, in _map_values\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/pandas/core/algorithms.py\", line 1743, in map_array\n    return lib.map_infer(values, mapper, convert=convert)\n  File \"lib.pyx\", line 2972, in pandas._libs.lib.map_infer\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/modin/pandas/series.py\", line 1268, in <lambda>\n    arg(s) if pandas.isnull(s) is not True or na_action is None else s\n  File \"/tmp/ipykernel_22696/2397226419.py\", line 7, in preprocess_text\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/__init__.py\", line 142, in word_tokenize\n    sentences = [text] if preserve_line else sent_tokenize(text, language)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/__init__.py\", line 119, in sent_tokenize\n    tokenizer = _get_punkt_tokenizer(language)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/__init__.py\", line 105, in _get_punkt_tokenizer\n    return PunktTokenizer(language)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/punkt.py\", line 1744, in __init__\n    self.load_lang(lang)\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/tokenize/punkt.py\", line 1749, in load_lang\n    lang_dir = find(f\"tokenizers/punkt_tab/{lang}/\")\n  File \"/home/lcda/miniconda3/envs/dl_with_pytorch/lib/python3.10/site-packages/nltk/data.py\", line 579, in find\n    raise LookupError(resource_not_found)\nLookupError: \n**********************************************************************\n  Resource \u001B[93mpunkt_tab\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt_tab/english/\u001B[0m\n\n  Searched in:\n    - '/home/lcda/nltk_data'\n    - '/home/lcda/miniconda3/envs/dl_with_pytorch/nltk_data'\n    - '/home/lcda/miniconda3/envs/dl_with_pytorch/share/nltk_data'\n    - '/home/lcda/miniconda3/envs/dl_with_pytorch/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 4: Feature Generation (TF-IDF)\n",
    "**Objective**: Convert the preprocessed text data into numerical features using TF-IDF.\n",
    "\n",
    "1. Use the `TfidfVectorizer` from `sklearn` to convert the reviews into numerical vectors.\n",
    "2. Limit the maximum number of features to 5,000 to reduce the dimensionality.\n",
    "3. Fit the vectorizer on the training set and transform both the training, validation and test sets.\n",
    "4. Print the shape of the transformed feature sets to confirm the conversion."
   ],
   "id": "8e0dd5545db5d361"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:09.421504Z",
     "start_time": "2024-10-04T08:58:09.419719Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a0ab295c4db2b89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 5: Building the MLP Model (PyTorch)\n",
    "**Objective**: Build a simple Multi-Layer Perceptron (MLP) for binary classification.\n",
    "\n",
    "1. Define the MLP model using `torch.nn.Module`. The model should have:\n",
    "    - An input layer that matches the size of the TF-IDF features.\n",
    "    - Two hidden layers with ReLU activations.\n",
    "    - A single output layer with a sigmoid activation function.\n",
    "2. Print the model summary.\n"
   ],
   "id": "61baaf1ab53478c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:09.466766Z",
     "start_time": "2024-10-04T08:58:09.464703Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5b8179e1ea1d73d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:10.396727Z",
     "start_time": "2024-10-04T08:58:10.395179Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8773057adff1116a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 6: Training the Model\n",
    "**Objective**: Train the MLP model on the training data.\n",
    "\n",
    "1. Convert the TF-IDF feature matrices and labels into PyTorch tensors (the label needs to be binarized).\n",
    "2. Define the loss function (`BCELoss` for binary classification) and the optimizer (`Adam`).\n",
    "3. Implement a training loop to train the model for a specified number of epochs (e.g., 50).\n",
    "4. Monitor the training and validation loss during training."
   ],
   "id": "d9266420be193ab7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:11.284843Z",
     "start_time": "2024-10-04T08:58:11.283287Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2698b469c554df8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:12.370745Z",
     "start_time": "2024-10-04T08:58:12.369210Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d316373ebf5c939a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:13.280467Z",
     "start_time": "2024-10-04T08:58:13.278957Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "2527b1bffa065bf1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 7: Model Evaluation\n",
    "**Objective**: Evaluate the performance of the trained model on the test data.\n",
    "\n",
    "1. Use the trained model to make predictions on the test set.\n",
    "2. Calculate the accuracy of the model on the test data.\n",
    "3. Print the test accuracy."
   ],
   "id": "98f0dec0e502aa8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:14.218747Z",
     "start_time": "2024-10-04T08:58:14.216975Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8d05d21ad2985d22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Exercise 8: Saving the Trained Model**\n",
    "\n",
    "1. Save the model's state_dict using `torch.save()`. \n",
    "\n",
    "2. Save the entire model, including its architecture and weights.\n",
    "\n",
    "3. Demonstrate how to load the saved model and use it for making predictions on new data."
   ],
   "id": "8d47e836e3bccbf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:15.209845Z",
     "start_time": "2024-10-04T08:58:15.208288Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ad160c9e1373b3fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:16.092378Z",
     "start_time": "2024-10-04T08:58:16.090902Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9146f5dd16930b67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:16.981545Z",
     "start_time": "2024-10-04T08:58:16.979910Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b65cb2f47000ed68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:17.864459Z",
     "start_time": "2024-10-04T08:58:17.862774Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fad2d5294a91a521",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:18.736133Z",
     "start_time": "2024-10-04T08:58:18.734495Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c1504f7c692bd8c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T08:58:19.601840Z",
     "start_time": "2024-10-04T08:58:19.600228Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5b387d061cdd19d2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
