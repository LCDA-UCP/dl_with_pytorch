{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# IMDB 50K Movie Reviews - Sentiment Classification with MLP\n",
    "\n",
    "## Overview\n",
    "\n",
    "### In the next exercises, you will work with the IMDB 50K Movie Reviews dataset to build a sentiment analysis model using a Multi-Layer Perceptron (MLP). You will practice essential steps in the data science pipeline such as data loading, preprocessing, feature generation, and training/testing a neural network model. This exercise should be completed using the `pandas`, `nltk`, `sklearn`, and `torch` libraries.\n"
   ],
   "id": "fbc88e3cb2c788d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 1: Data Loading and Exploration\n",
    "**Objective**: Load the IMDB dataset and explore its structure.\n",
    "\n",
    "1. **Load the dataset** using `pandas`. The dataset is in the `data/` folder and the file name is `imdb_dataset.zip`. **Hint: you can load zip files with pandas by passing `compression='zip'` tp `pd.read_csv`**\n",
    "2. **Explore the dataset** by checking for missing values and getting a summary of the data. \n",
    "    - Check the shape of the dataset.\n",
    "    - Get the distribution of the sentiment labels (positive/negative reviews).\n",
    "3. Print the first few reviews and their corresponding labels.\n"
   ],
   "id": "1967f805bf9ca917"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T17:13:01.209453Z",
     "start_time": "2024-10-03T17:13:00.177717Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows x 2 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18,
   "source": [
    "import modin.pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/imdb_dataset.zip', compression='zip')\n",
    "df"
   ],
   "id": "a53cce52163c4447"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T17:13:03.035920Z",
     "start_time": "2024-10-03T17:13:03.034209Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 2)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19,
   "source": [
    "df.shape "
   ],
   "id": "e57bb2bb70f9f4ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T17:13:04.366886Z",
     "start_time": "2024-10-03T17:13:04.101419Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\nnegative    25000\npositive    25000\nName: count, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20,
   "source": [
    "df['sentiment'].value_counts()"
   ],
   "id": "6388a96dd14227db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 2: Splitting the Data\n",
    "**Objective**: Split the data into training, validation and test sets.\n",
    "\n",
    "1. Split the dataset into features (reviews) and labels (sentiment).\n",
    "2. Use `train_test_split` from `sklearn` to split the dataset into training, validation and test sets (use an 60/20/20 split).\n",
    "3. Print the sizes of the training and test sets to ensure the splits were done correctly."
   ],
   "id": "d50a1d1bcc857961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T17:13:06.530612Z",
     "start_time": "2024-10-03T17:13:06.335633Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((40000, 2), (10000, 2))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df['sentiment'])\n",
    "\n",
    "train.shape, test.shape\n"
   ],
   "id": "1cd385320714117c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T17:13:08.252569Z",
     "start_time": "2024-10-03T17:13:08.064901Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((30000, 2), (10000, 2), (10000, 2))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22,
   "source": [
    "train, valid = train_test_split(train, test_size=0.25, stratify=train['sentiment'])\n",
    "\n",
    "train.shape, valid.shape, test.shape"
   ],
   "id": "7543576eeb9d21ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "cb278e805672ee97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 3: Text Preprocessing\n",
    "**Objective**: Preprocess the text data to prepare it for feature generation.\n",
    "\n",
    "1. Lowercase the text data. **Hint: python has a built-in string method for this**.\n",
    "2. Remove any URL from the reviews. **Hint: you can use regular expressions for this**.\n",
    "3. Remove non-word and non-whitespace characters (punctuation, special characters, etc.). **Hint: you can use regular expressions for this**.\n",
    "4. Remove digits. **Hint: you can use regular expressions for this**.\n",
    "5. Tokenize the reviews into individual words. **Hint: you can use the `nltk` library for this**.\n",
    "6. Remove stopwords. **Hint: you can use the `nltk` library for this**.\n",
    "7. Perform stemming or lemmatization. **Hint: you can use the `nltk` library for this**.\n",
    "8. Apply the preprocessing steps to both the training and test sets."
   ],
   "id": "2565a8072f03328a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "274001c7274aa06d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "20728d8e4d17ae5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "838d9aed37b5086b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 4: Feature Generation (TF-IDF)\n",
    "**Objective**: Convert the preprocessed text data into numerical features using TF-IDF.\n",
    "\n",
    "1. Use the `TfidfVectorizer` from `sklearn` to convert the reviews into numerical vectors.\n",
    "2. Limit the maximum number of features to 5,000 to reduce the dimensionality.\n",
    "3. Fit the vectorizer on the training set and transform both the training and test sets.\n",
    "4. Print the shape of the transformed feature sets to confirm the conversion."
   ],
   "id": "8e0dd5545db5d361"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "a0ab295c4db2b89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "856f18c5c94325fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "1b8a0ea222222ca8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 5: Building the MLP Model (PyTorch)\n",
    "**Objective**: Build a simple Multi-Layer Perceptron (MLP) for binary classification.\n",
    "\n",
    "1. Define the MLP model using `torch.nn.Module`. The model should have:\n",
    "    - An input layer that matches the size of the TF-IDF features.\n",
    "    - Two hidden layers with ReLU activations.\n",
    "    - A single output layer with a sigmoid activation function.\n",
    "2. Print the model summary.\n"
   ],
   "id": "61baaf1ab53478c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "5b8179e1ea1d73d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "8773057adff1116a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "2c1940fce63dbe6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 6: Training the Model\n",
    "**Objective**: Train the MLP model on the training data.\n",
    "\n",
    "1. Convert the TF-IDF feature matrices and labels into PyTorch tensors (the label needs to be binarized).\n",
    "2. Define the loss function (`BCELoss` for binary classification) and the optimizer (`Adam`).\n",
    "3. Implement a training loop to train the model for a specified number of epochs (e.g., 50).\n",
    "4. Monitor the training and validation loss during training."
   ],
   "id": "d9266420be193ab7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "2698b469c554df8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "d316373ebf5c939a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "2527b1bffa065bf1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 7: Model Evaluation\n",
    "**Objective**: Evaluate the performance of the trained model on the test data.\n",
    "\n",
    "1. Use the trained model to make predictions on the test set.\n",
    "2. Calculate the accuracy of the model on the test data.\n",
    "3. Print the test accuracy."
   ],
   "id": "98f0dec0e502aa8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "8d05d21ad2985d22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "64f4e2de866c19d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "5fbd772b66c97eb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Exercise 8: Saving the Trained Model**\n",
    "\n",
    "1. Save the model's state_dict using `torch.save()`. \n",
    "\n",
    "2. Save the entire model, including its architecture and weights.\n",
    "\n",
    "3. Demonstrate how to load the saved model and use it for making predictions on new data.\n"
   ],
   "id": "59a7f161b7501957"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T20:10:02.712871Z",
     "start_time": "2024-10-02T20:10:02.710085Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "349c9b2452e8c98f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T20:10:02.757446Z",
     "start_time": "2024-10-02T20:10:02.755128Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "7e62e6f700facf51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "2043076079637bd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
