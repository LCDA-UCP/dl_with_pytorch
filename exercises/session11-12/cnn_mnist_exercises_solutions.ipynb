{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf2cd67a7fb4ec1",
   "metadata": {},
   "source": [
    "# CNN Tutorial with PyTorch on the MNIST Dataset\n",
    "\n",
    "In this tutorial, we will build a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset. We'll go through the following steps:\n",
    "\n",
    "1. **Data Loading, Processing, and Augmentation**\n",
    "2. **Data Exploration**\n",
    "3. **Model Building**\n",
    "4. **Model Training**\n",
    "5. **Model Evaluation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de854ac82e9a020b",
   "metadata": {},
   "source": [
    "## 1. Data Loading, Processing, and Augmentation\n",
    "\n",
    "The MNIST dataset consists of 28x28 pixel grayscale images of handwritten digits (0-9). We'll use PyTorch's `torchvision` to load and preprocess the data. We will also apply some augmentations to improve our model's robustness.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "1. Import the necessary libraries.\n",
    "2. Load the MNIST dataset using `torchvision.datasets`.\n",
    "3. Apply normalization to the dataset.\n",
    "4. Create data loaders for training and testing with appropriate batch sizes.\n",
    "5. Experiment with different data augmentations like rotation, translation, and flipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98248f80f8d704a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:46:29.315017Z",
     "start_time": "2024-11-06T21:46:26.698121Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [0, 1]\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d35a16ffac61778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:46:29.728309Z",
     "start_time": "2024-11-06T21:46:29.321765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20c90583c70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "example_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=30),  # Rotate by a random angle\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Translate by a random fraction\n",
    "    transforms.RandomHorizontalFlip(p=0.5)  # Flip horizontally with a 50% probability\n",
    "])\n",
    "\n",
    "# Apply the transformations to a sample image\n",
    "example_image = train_dataset[2][0]\n",
    "# show the original image\n",
    "plt.imshow(example_image.numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b973103232079f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:46:29.894337Z",
     "start_time": "2024-11-06T21:46:29.810749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20c9178f340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformed_image = example_transform(example_image)\n",
    "plt.imshow(transformed_image.numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d4b41cceb7666",
   "metadata": {},
   "source": [
    "## 2. Data Exploration\n",
    "\n",
    "Before training our model, it's essential to explore the data. This helps us understand its distribution and visualize some examples.\n",
    "\n",
    "### Exercise\n",
    "1. Visualize a few images from the training dataset along with their labels.\n",
    "2. Print the number of samples in the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3e17130dd15243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:46:30.173485Z",
     "start_time": "2024-11-06T21:46:29.906852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAAH4CAYAAAAGiH8MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAs10lEQVR4nO3df5TVdZ0/8NcFFAEzQcVMUvEoAYWmIKKZopj4ox/QkrnHZKkwl/RE/kjTBOxYR2mxzFBBUYGw9viDcV1zcdcEPRY/NQlUFFJSLPllCCyo4NzvH31j14XPe4bLDDPvO4/HOZ5j93lfn/uewXk3Tz4z910ql8vlAAAAIFutmnoBAAAA7BrFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJA5xa6ZWr58eZRKpRg3blyDXXPWrFlRKpVi1qxZDXZNgN3N/giwY/bHlk2xa0CTJ0+OUqkUCxYsaOqlNJrHH388Tj311Nh///1j3333jb59+8YvfvGLpl4W0MxV+/5YU1MTAwcOjI9+9KPRtm3b6NKlSwwZMiQWL17c1EsDmrlq3x//r89+9rNRKpXikksuaeqlVJ02Tb0A8vHwww/HoEGD4oQTTojrrrsuSqVS3HfffTF06NBYs2ZNXHrppU29RIAmsWjRoujYsWOMHDky9t9//3jzzTfj7rvvjr59+8bs2bPj6KOPbuolAjS56dOnx+zZs5t6GVVLsaPexo8fHwcddFA88cQT0bZt24iIuOiii6J79+4xefJkxQ5osUaPHr3dY8OHD48uXbrE7bffHhMmTGiCVQE0H++8805cfvnlcdVVV+1wz2TX+VHM3ey9996L0aNHR+/evePDH/5wdOjQIT7zmc/EzJkzC2d++tOfxqGHHhrt2rWLU045ZYc/2rNkyZIYMmRIdOrUKfbaa6/o06dPPPzww3WuZ9OmTbFkyZJYs2ZNnc9dv359dOzYcVupi4ho06ZN7L///tGuXbs65wFSct4fd6Rz587Rvn37WLduXUXzAH9XDfvjj3/846itrY0rrrii3jPsHMVuN1u/fn1MmjQp+vfvH2PHjo3rrrsuVq9eHQMHDoznnntuu+dPnTo1brnllrj44ovj6quvjsWLF8dpp50WK1eu3Pac559/Pvr16xcvvvhifO9734ubbropOnToEIMGDYqamprkeubNmxc9evSI8ePH17n2/v37x/PPPx+jRo2KZcuWxR//+Me4/vrrY8GCBXHllVfu9OcC4H/LeX/8u3Xr1sXq1atj0aJFMXz48Fi/fn0MGDCg3vMAO5L7/vjaa6/FjTfeGGPHjnUzoDGVaTD33HNPOSLK8+fPL3zO1q1by+++++4HHvvrX/9aPvDAA8tf//rXtz326quvliOi3K5du/KKFSu2PT537txyRJQvvfTSbY8NGDCg3KtXr/I777yz7bHa2tryiSeeWD7yyCO3PTZz5sxyRJRnzpy53WNjxoyp8+PbuHFj+dxzzy2XSqVyRJQjoty+ffvyQw89VOcs0LJV+/74dx//+Me37Y977713+dprry2///779Z4HWp6WsD8OGTKkfOKJJ2773xFRvvjii+s1S/25Y7ebtW7dOvbcc8+IiKitrY233nortm7dGn369Ilnn312u+cPGjQoDj744G3/u2/fvnH88cfHo48+GhERb731VjzxxBNx7rnnxoYNG2LNmjWxZs2aWLt2bQwcODCWLl0ab7zxRuF6+vfvH+VyOa677ro61962bdvo1q1bDBkyJH71q1/FtGnTok+fPvHVr3415syZs5OfCYAPynl//Lt77rknZsyYEbfddlv06NEjNm/eHO+//3695wF2JOf9cebMmfHggw/GzTffvHMfNDvNm6c0gSlTpsRNN90US5YsiS1btmx7vGvXrts998gjj9zusW7dusV9990XERHLli2Lcrkco0aNilGjRu3w9VatWvWBL+5KXXLJJTFnzpx49tlno1Wrv/2dwLnnnhuf+MQnYuTIkTF37txdfg2gZct1f/y7E044Ydu/n3feedGjR4+IiAY9UwpomXLcH7du3Rrf/va344ILLojjjjtul65F3RS73WzatGkxbNiwGDRoUHz3u9+Nzp07R+vWreOGG26IP/7xjzt9vdra2oiIuOKKK2LgwIE7fM4RRxyxS2uO+Nsv7d51111x5ZVXbit1ERF77LFHnHXWWTF+/Ph47733tv1tEsDOynV/LNKxY8c47bTT4t5771XsgF2S6/44derUeOmll2LixImxfPnyD2QbNmyI5cuXb3ujKXadYrebPfDAA3H44YfH9OnTo1QqbXt8zJgxO3z+0qVLt3vs5ZdfjsMOOywiIg4//PCI+FvBOv300xt+wf/f2rVrY+vWrTv8kaItW7ZEbW2tHzcCdkmu+2PK5s2b4+23326S1waqR67742uvvRZbtmyJT3/609tlU6dOjalTp0ZNTU0MGjSo0dbQkvgdu92sdevWERFRLpe3PTZ37tzCwxofeuihD/yM87x582Lu3Llx1llnRcTf3k67f//+MXHixPjLX/6y3fzq1auT66nv29V27tw59t1336ipqYn33ntv2+MbN26Mf//3f4/u3bt7lyNgl+S6P0b87UeW/q/ly5fHb37zm+jTp0+d8wApue6P5513XtTU1Gz3T0TE2WefHTU1NXH88ccnr0H9uWPXCO6+++6YMWPGdo+PHDkyPve5z8X06dNj8ODBcc4558Srr74aEyZMiJ49e8bGjRu3mzniiCPipJNOihEjRsS7774bN998c+y3334fOF7g1ltvjZNOOil69eoVF154YRx++OGxcuXKmD17dqxYsSIWLlxYuNZ58+bFqaeeGmPGjEn+Amzr1q3jiiuuiGuvvTb69esXQ4cOjffffz/uuuuuWLFiRUybNm3nPklAi1SN+2NERK9evWLAgAHxqU99Kjp27BhLly6Nu+66K7Zs2RI33nhj/T9BQItVjftj9+7do3v37jvMunbt6k5dA1PsGsHtt9++w8eHDRsWw4YNizfffDMmTpwYjz32WPTs2TOmTZsW999/f8yaNWu7maFDh0arVq3i5ptvjlWrVkXfvn1j/PjxcdBBB217Ts+ePWPBggXxgx/8ICZPnhxr166Nzp07xzHHHBOjR49usI/r+9//fnTt2jV+9rOfxQ9+8IN4991346ijjooHHngg/uEf/qHBXgeoXtW6P44YMSJ+/etfx4wZM2LDhg3RuXPnOOOMM+Kaa66JXr16NdjrANWrWvdHdp9S+X/f0wUAACA7fscOAAAgc4odAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyFy9DygvlUqNuQ5oERwbWZ3sj7Dr7I/Vyf4IDaM+e6Q7dgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJA5xQ4AACBzih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJC5Nk29AABajn333bcwe++99yq+7n777ZfM161bV5ht2LCh4tcFgObCHTsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQuVK5XC7X64mlUmOvhYi4/vrrC7Nzzz03OdutW7fCbOPGjcnZBx54oDD72c9+lpx97rnnkjn/o55fbmTG/lh/v/zlLwuzj33sY8nZVq2K/y7y+OOPT84uWrSoMHv55ZeTsynPPvtsMv/FL35RmP35z3+u+HWrkf2xOtkfoWHUZ490xw4AACBzih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADInHPsGkHr1q0Ls0cffTQ5e/rppxdmTfVnsGXLlmT++OOPF2bz589Pzj788MOFWV3nQ+XIOU3Vyf5Yf23bti3MjjnmmOTs5ZdfXpgNHjw4OZv6M2rMr8vXX3+9MHvmmWeSs+PGjSvM5syZU/Gamiv7Y3VqaftjXedxrl+/vjB7++23G3o5VBHn2AEAALQAih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkznEHjaBdu3aF2X//939XfN1zzjknmS9cuLDia1988cUVZRER++yzT8WvO2/evMKsX79+FV+3ufJ23tXJ/rh7tG/fvjDr1KlTo73ueeedV5gdeOCBydnLLrusMKtrP9i8eXNFa4qI+PWvf53MmyP7Y3Wqxv3xsMMOK8xmzZqVnJ0xY0Zh9s///M8Vroj/6yMf+UgyP/fccwuzW265paGX0yAcdwAAANACKHYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc86xawR77bVXYbZq1ark7N57712Y1XWe3O23355eWIUOOeSQZJ46L+kTn/hEctY5dlQD+yOVuOuuu5L5sGHDKr5269atK55tKvbH6lSN++O4ceMKs3/6p39Kzg4ePLgwe/rppyteEx/0hz/8IZl/8pOfLMxatWqe972cYwcAANACKHYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQuTZNvYBq9M477xRmjz/+eHJ20KBBhVldb319xx13FGbvv/9+cjbl9ddfT+avvPJKYVbXcQcALdUjjzySzOt623SgcXznO99J5hdddFFh9uijjyZnHWnQcFLfY3bv3j05e9999zX0cpoFd+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hQ7AACAzDnHbje7++67k/k555xTmB133HHJ2a997WuF2aRJk9ILSzjzzDOT+ec///mKr70r5+sBNHc///nPC7OvfOUru3ElwP+2//77F2ZXXXVVcnbJkiWFmfMnd59PfepThdkee+yRnF2/fn0Dr6Z5cMcOAAAgc4odAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZM5xB7vZI488ksz/9V//tTC74IILkrPXXnttYXb//fcnZ7t06VKY1XVEQ8of/vCHZD506NCKrw3wd717907mJ598cqO87vDhw5N59+7dC7NyuZycffnllwuzL33pS+mFAUk33nhjYXbggQcmZ5988snC7J133ql4TeycDh06VDz7y1/+sgFX0ny4YwcAAJA5xQ4AACBzih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkrlSu6yCdvz+xVGrstRDp8+RefPHF5GzqPI8nnngiOdu/f//CrFWrdP9fuXJlYXbdddclZydOnJjMq009v9zIjP1x9/jyl79cmKXOAI1I72O1tbUVr6kub7zxRmF25ZVXJmfr+piqjf2xOjXV/njOOeck8zvvvLMwe/PNN5OzZ555ZmG2atWq9MKot7333juZz549uzCr64y7Y445pjB7++230wtrIvXZI92xAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlz3EFGHnvssWT+2c9+tlFet6637h0zZkxh1tKOM6iLt/OuTvbH3SN1HEy/fv0a7XW/9a1vFWYnn3xycvZ3v/tdYTZ48ODk7Nq1a9MLqzL2x+rUmPvj0UcfXZg9/vjjydn99tuvMJs/f35ydq+99irM1qxZk5z9/e9/X5hNnTo1Obts2bLCbNOmTcnZHPXu3TuZp/6cFi1alJxN/bfTXDnuAAAAoAVQ7AAAADKn2AEAAGROsQMAAMicYgcAAJA5xQ4AACBzih0AAEDm2jT1Aqi/l19+OZnvyjl2b7zxRmE2YsSI5OwjjzxS8esC1NeKFSsKswceeKDRXnfmzJmF2bXXXpuc/fa3v12YffOb30zO3nDDDemFQQuXOt83dU5dRMSbb75ZmL3yyivJ2a985SvphSWceuqphdlll12WnE2dzfYf//Efydl/+Zd/Kcya65mZQ4YMSeapMxKXLl3a0MvJgjt2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyJxiBwAAkDnFDgAAIHOlcrlcrtcTE28pyu7xxBNPJPP+/ftXfO3x48cXZqm362bn1PPLjczYH1uuD33oQ8l83bp1hdny5cuTsyeddFJh9pe//CU5myP7Y3VqzP0x9d/M/fffn5wdNWpUYVbX8VKtW7dOL6xCI0eOTOaXXHJJYXbooYcmZxcvXlyYTZ8+PTn70EMPJfPnnnsumVfqzjvvTObf+MY3CrPzzz8/OfurX/2qojU1pfrske7YAQAAZE6xAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlzjl0zM3To0MJs0qRJydk2bdpU/Lr/+Z//WZideeaZFV+XD3JOU3VqrP1xv/32q3h27dq1DbgSKpX6mn/11VeTs5/+9KcLM+fYkYvG/P7x2GOPLcxefPHF5OzmzZsbejmNLvX/CanPRUTENddcU5ilzsyMqPvPcOHChcm8UkcddVQyb9Wq+P7U3nvvnZzN8c/fOXYAAAAtgGIHAACQOcUOAAAgc4odAABA5hQ7AACAzCl2AAAAmXPcwW526qmnJvMpU6YUZgcddFBydtasWYXZgAEDkrNbtmwpzFJvuR0RsWDBgmTO//B23tVpV/bHfv36FWbXX399cnbRokWF2WWXXVbxmmg477//fmH2u9/9Ljn7mc98pqGX06zZH6uT7x+bvwMPPDCZDxw4MJkffPDBhdnZZ5+dnO3Zs2dh1qlTp+TsL3/5y8Ls/PPPT87myHEHAAAALYBiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADLXpqkXUI1OOeWUwmzq1KnJ2dRZIIMHD07Ops6xW7hwYXL2kEMOKcy+8IUvJGedYweV++1vf1uYpc6pi4gYM2ZMQy+HnfSP//iPFc8uXbq0AVcCUJmVK1cm87q+d0254YYbkvk3v/nNwmzChAnJ2ffee6+iNVUzd+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hx3UIE999wzmf/kJz8pzFLHGUREXH/99YXZww8/nJwtl8uF2fr165OzKamjEIDG061bt2T+la98pTCbNGlSQy+nxUr9Odx4443J2Y0bNxZmP/vZzypeE0A1+PznP1/x7JQpUxpwJdXBHTsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc86xq8AjjzySzI855pjC7De/+U1yduzYsYVZ6pw6IE/77rtvYfbUU08lZydOnFhRFhHxwx/+sDBrzDPwXn/99Ua7dsrHPvaxwuycc85Jzo4aNaow+8hHPpKcveOOOwqzhQsXJmcBcte6detk3q5du8LsT3/6U3J2zpw5Fa2pmrljBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADLnuIMCe+65Z2F24IEHVnzdW2+9NZlv2rSp4mv36dOnMOvWrVvF1wUaz4YNGwqzESNGJGdPPfXUwiz1Fv0REddee21h9v3vfz85uysefPDBRrt2ypAhQwqzuo6SWbt2bWH2jW98Izk7efLkZA5Qzer6nvm0004rzG6//fbk7DvvvFPRmqqZO3YAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5pxjV2CfffYpzPbff/+Kr/vFL34xmT/zzDOFWW1tbXJ29OjRhVnqXL66rv1v//ZvyVmgccyZM6fi/LHHHkvOXnnllRWtKSLi4IMPLsxOOOGE5OyunCe3K+6///7C7M9//nNy9rbbbivMli1bVvGaACj2+uuvN/USsuOOHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMhcqVzP95culUqNvZZs3HPPPcn8/PPPL8zatGmeJ0zce++9hdkFF1ywG1dS3Rrz7dxpOi1tf2zfvn1h1qlTp924kvpbsWJFUy+BOtgfq1NL2x/5oOHDhyfzO+64ozA76qijkrOLFy+uaE25qs8e6Y4dAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyJxiBwAAkLnmeahaM/e1r30tmU+aNKkw+9WvfpWc7dKlS0Vrioh47rnnCrMHH3wwOXvbbbdV/LpAy7Jp06aKMgBalr322iuZr1+/vjBz/ujOc8cOAAAgc4odAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZK5ULpfL9XpiqdTYa4GqV88vNzJjf4RdZ3+sTvbHlm3PPfdM5occckhhtmzZsoZeTtbqs0e6YwcAAJA5xQ4AACBzih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkzjl2sBs5p6k62R9h19kfq5P9ERqGc+wAAABaAMUOAAAgc4odAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADJXKpfL5aZeBAAAAJVzxw4AACBzih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpds3U8uXLo1Qqxbhx4xrsmrNmzYpSqRSzZs1qsGsC7G72R4Adsz+2bIpdA5o8eXKUSqVYsGBBUy9lt/jsZz8bpVIpLrnkkqZeCtDMVfv++NJLL8Wll14aJ554Yuy1115RKpVi+fLlTb0sIAPVvj/W1NTEwIED46Mf/Wi0bds2unTpEkOGDInFixc39dKqjmJHRaZPnx6zZ89u6mUANAuzZ8+OW265JTZs2BA9evRo6uUANBuLFi2Kjh07xsiRI+O2226LESNGxO9///vo27dvLFy4sKmXV1XaNPUCyM8777wTl19+eVx11VUxevTopl4OQJP7whe+EOvWrYsPfehDMW7cuHjuueeaekkAzcKOvlccPnx4dOnSJW6//faYMGFCE6yqOrljt5u99957MXr06Ojdu3d8+MMfjg4dOsRnPvOZmDlzZuHMT3/60zj00EOjXbt2ccopp+zw1vWSJUtiyJAh0alTp9hrr72iT58+8fDDD9e5nk2bNsWSJUtizZo19f4YfvzjH0dtbW1cccUV9Z4BqEvO+2OnTp3iQx/6UJ3PA6hEzvvjjnTu3Dnat28f69atq2ieHVPsdrP169fHpEmTon///jF27Ni47rrrYvXq1TFw4MAd/g3v1KlT45ZbbomLL744rr766li8eHGcdtppsXLlym3Pef7556Nfv37x4osvxve+97246aabokOHDjFo0KCoqalJrmfevHnRo0ePGD9+fL3W/9prr8WNN94YY8eOjXbt2u3Uxw6Qkvv+CNBYqmF/XLduXaxevToWLVoUw4cPj/Xr18eAAQPqPU/d/CjmbtaxY8dYvnx57Lnnntseu/DCC6N79+7x85//PO66664PPH/ZsmWxdOnSOPjggyMi4swzz4zjjz8+xo4dGz/5yU8iImLkyJFxyCGHxPz586Nt27YREfGtb30rTjrppLjqqqti8ODBDbb+yy+/PI455pg477zzGuyaABH5748AjaUa9sd+/frFSy+9FBERe++9d1x77bXxjW98o0Ffo6Vzx243a9269bYvytra2njrrbdi69at0adPn3j22We3e/6gQYO2fVFGRPTt2zeOP/74ePTRRyMi4q233oonnngizj333NiwYUOsWbMm1qxZE2vXro2BAwfG0qVL44033ihcT//+/aNcLsd1111X59pnzpwZDz74YNx8880790ED1EPO+yNAY6qG/fGee+6JGTNmxG233RY9evSIzZs3x/vvv1/veermjl0TmDJlStx0002xZMmS2LJly7bHu3btut1zjzzyyO0e69atW9x3330R8be/kSmXyzFq1KgYNWrUDl9v1apVH/jirsTWrVvj29/+dlxwwQVx3HHH7dK1AIrkuD8C7A65748nnHDCtn8/77zztr2DcEOeudfSKXa72bRp02LYsGExaNCg+O53vxudO3eO1q1bxw033BB//OMfd/p6tbW1ERFxxRVXxMCBA3f4nCOOOGKX1hzxt5/Vfumll2LixInbnc20YcOGWL58+bZfhAWoRK77I0Bjq7b9sWPHjnHaaafFvffeq9g1IMVuN3vggQfi8MMPj+nTp0epVNr2+JgxY3b4/KVLl2732MsvvxyHHXZYREQcfvjhERGxxx57xOmnn97wC/7/XnvttdiyZUt8+tOf3i6bOnVqTJ06NWpqamLQoEGNtgaguuW6PwI0tmrcHzdv3hxvv/12k7x2tfI7drtZ69atIyKiXC5ve2zu3LmFh30/9NBDH/gZ53nz5sXcuXPjrLPOioi/vV1s//79Y+LEifGXv/xlu/nVq1cn11Pft6s977zzoqamZrt/IiLOPvvsqKmpieOPPz55DYCUXPdHgMaW8/64atWq7R5bvnx5/OY3v4k+ffrUOU/9uWPXCO6+++6YMWPGdo+PHDkyPve5z8X06dNj8ODBcc4558Srr74aEyZMiJ49e8bGjRu3mzniiCPipJNOihEjRsS7774bN998c+y3335x5ZVXbnvOrbfeGieddFL06tUrLrzwwjj88MNj5cqVMXv27FixYkUsXLiwcK3z5s2LU089NcaMGZP8Bdju3btH9+7dd5h17drVnTqgXqpxf4yIePvtt+PnP/95RET89re/jYiI8ePHx7777hv77rtvXHLJJfX59AAtWLXuj7169YoBAwbEpz71qejYsWMsXbo07rrrrtiyZUvceOON9f8EUSfFrhHcfvvtO3x82LBhMWzYsHjzzTdj4sSJ8dhjj0XPnj1j2rRpcf/998esWbO2mxk6dGi0atUqbr755li1alX07ds3xo8fHwcddNC25/Ts2TMWLFgQP/jBD2Ly5Mmxdu3a6Ny5cxxzzDExevToxvowAXZate6Pf/3rX7d7A4KbbropIiIOPfRQxQ6oU7XujyNGjIhf//rXMWPGjNiwYUN07tw5zjjjjLjmmmuiV69eDfY6RJTK//ueLgAAANnxO3YAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5up9QHmpVGrMdUCL4ejI6mN/hIZhf6w+9kdoGPXZH92xAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJA5xQ4AACBzih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMy1aeoFAEBj69ChQzJ/8sknk/kee+xRmB199NEVrQngfxs8eHAy/+pXv1qYDRo0KDlbKpUKs3K5XPFsRMT06dMLs1tuuSU5+9RTTyVzdo47dgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJA5xQ4AACBzjjugyQ0YMKAwu/fee5Ozp5xySmH20ksvVbwmoLqMGTMmmffu3TuZL1y4sCGXA7RQ3//+9wuz733ve8nZ9u3bF2Z1HVmQsiuzEemjFuraW++4447C7IYbbqh0SS2WO3YAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5pr9OXYnn3xyMt9vv/0Ks5qamoZeDo3guOOOK8zmz5+/G1cCVKt27drt0vwBBxxQmB122GHJ2eXLl+/SawPV4/zzzy/MNm3alJx9+umnC7O6vuddsmRJYVZbW5uc/dKXvpTMe/ToUZgNHDgwOfvDH/6wMEutOcL3+Tvijh0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADIXLM/7qB///7J/MgjjyzMvA1q89CqVfrvD7p27VqYHXroocnZUqlU0ZqAluVPf/rTLs2vXr26MHOcAVBfTz75ZGF25513JmefffbZhl5OvaSOWajL9ddfn8yvvvrqwmzq1KnJ2dRxWXUdlVCt3LEDAADInGIHAACQOcUOAAAgc4odAABA5hQ7AACAzCl2AAAAmVPsAAAAMlcql8vlej2xic4LW7ZsWTKfPXt2YXbBBRc09HKowMEHH5zMX3/99cJs2rRpydmhQ4dWtKamVM8vOTLiPMXm75VXXknmqfM0IyIuuuiiwuyOO+6oaE1sz/5YfeyPLdsBBxyQzOfNm1eYHXbYYcnZ3r17F2ZNdeZfY6rP/uiOHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMhcm6ZeQF1atdI9czdp0qSKZ5cuXdqAKwGqWeqtrw888MDk7MaNG5P5008/XdGaAFqy1atXJ/M1a9YUZoccckhDL6fqaU0AAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5prFOXZHHXVUYVbX2UM0fx/+8Icrnv2v//qvBlwJUM1OPvnkwqxdu3bJ2VWrViXzF154oaI1AbRkZ555ZjJPnVX37LPPJmfrylsid+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5prFcQdnn312YVbXW1TTPKSOpejatWvF133jjTcqngValmHDhjX1EgCapdRxMFdffXVydv/996/4dY899thknjpK5oILLqj4dVsqd+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hQ7AACAzDWLc+w+/vGPVzz7/PPPN+BKqNS4ceMKs9QZdxERL7/8cmG2YcOGitcEUF9Tpkxp6iUANJoJEyYUZnV9H14qlZJ5uVyueHbt2rWF2ZIlS5KzbM8dOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJC5ZnHcwa6YP39+Uy8hG/vss08yP/PMMwuzr371q8nZM844o6I1RURcf/31hdm6desqvi5Afa1evbqplwDQaF544YXCrFu3brt07dRxB3Xp3r37Lr02H+SOHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJC57M+x69SpU5O87tFHH12YlUql5Ozpp59emHXp0iU5u+eeexZm559/fnK2Vat0j9+8eXNhNnfu3OTsu+++W5i1aZP+z+yZZ55J5gAREW3btk3me+yxR2FW1748bty4itYEkIMhQ4Y02rVTZ9E99dRTydkDDjigoizC+aM74o4dAABA5hQ7AACAzCl2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyFypXC6X6/XEOt4qelfcdttthdlFF12UnF23bl1h9tprr1W6pDodddRRhVldn6utW7cWZps2bUrOvvDCC4VZXUcSLFiwIJk/+eSThdnKlSuTsytWrCjMOnbsmJxNHeFQjer5JUdGGnN/5H+cccYZyXzGjBkVX7uu42DYPeyP1cf+2LJNmDAhmQ8fPrwwu+WWW5Kzl112WUVrylV99kf/TwYAAJA5xQ4AACBzih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkrk1TLyAi4lvf+lZh9qc//Sk5e+KJJzb0cuoldUbeQw89lJx98cUXC7M5c+ZUuqRG9c1vfjOZH3DAAYXZK6+80tDLAQCgmbvzzjuT+YUXXliY9ejRo6GXU/XcsQMAAMicYgcAAJA5xQ4AACBzih0AAEDmFDsAAIDMKXYAAACZaxbHHaSMHTu2qZdARAwYMKDi2QcffLABVwKw86ZMmdLUSwBoceo6suCFF14ozH70ox819HKqnjt2AAAAmVPsAAAAMqfYAQAAZE6xAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOaa/Tl25K+mpqaplwC0cEOGDEnmX/va13bTSoDmrnv37sm8c+fOhdlTTz3V0MvJ2gEHHJDMW7Uqvsf09NNPN/Ryqp47dgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJA5xQ4AACBzjjsAoCqUSqXCbO+9996NKwGau9SRBvPnz0/O3nnnnYWZ4w4+aNCgQcm8trZ29yykhXDHDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMicc+xoEKnzo7p165acnTNnTkMvB6hCixcvTuavvfZaYfaxj32soZcDZCx1tmX79u2Ts5deemlh9swzzyRn77333vTCmqEOHTok86lTpxZmxx57bHJ26NChFa2JHXPHDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGTOcQc0iHK5XJi1auXvD4Bd9+c//zmZr1u3rjCr67iDL3/5y8n8/vvvT+ZAXlLft6SyiIja2trCbMqUKcnZ73znO4XZ9OnTk7M33HBDMk854IADCrPBgwcnZwcOHJjMv/jFLxZmo0aNSs7W1NQkc3aO77gBAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hQ7AACAzDnHjkZ3wgknJPPJkyfvnoUAVe2FF14ozHr16pWcret8qM2bNxdmjzzySHphQLPzzDPPFGaf/OQnk7Op8+Y+/vGPJ2d79+5dmB177LHJ2R/96EeFWV1n75VKpUaZrWtdu3L2HjvPHTsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOccd0CDqeitcgMb29a9/vTDbZ599krNnn312Mv/iF79YmDnuAKrLkiVLknmfPn0Ks8GDBydnr7nmmsKsrqMSUuo6smBXZocOHZrMa2pqKn5tGpY7dgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJA5xQ4AACBzih0AAEDmSuV6HnzhnLKWbdiwYcn87rvvLszuvPPO5OxFF11UyZKytStnzdA82R+hYdgfq4/9ERpGffZHd+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hx3ALuZt/OuPvZHaBj2x+pjf4SG4bgDAACAFkCxAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMicYgcAAJA5xQ4AACBzih0AAEDmFDsAAIDMKXYAAACZU+wAAAAyp9gBAABkTrEDAADInGIHAACQOcUOAAAgc4odAABA5hQ7AACAzJXK5XK5qRcBAABA5dyxAwAAyJxiBwAAkDnFDgAAIHOKHQAAQOYUOwAAgMwpdgAAAJlT7AAAADKn2AEAAGROsQMAAMjc/wOua9r80E0eJAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display images\n",
    "def show_images(images, labels):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(6):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().squeeze(), cmap='gray')\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some samples from the training dataset\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Show images\n",
    "show_images(images, labels)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Test samples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf01dbc897fa0e3",
   "metadata": {},
   "source": [
    "## 3. Model Building\n",
    "\n",
    "Now, we'll define our CNN architecture. A typical CNN consists of convolutional layers, activation functions, pooling layers, and a fully connected output layer.\n",
    "\n",
    "### Exercise\n",
    "1. Define a CNN class inheriting from torch.nn.Module.\n",
    "2. Include two convolutional layers, ReLU activations, max pooling, and a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86bc9381447392ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:46:30.194900Z",
     "start_time": "2024-11-06T21:46:30.188268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Input: 1 channel, Output: 32 channels\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # Input: 32 channels, Output: 64 channels\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Apply first convolution and ReLU, Input size: 28x28, 1 channel, Output size: 28x28, 32 channels\n",
    "        x = F.max_pool2d(x, 2)  # Max pooling, Output size: 14x14 (max pooling with kernel size 2 reduces dimensions by half)\n",
    "        x = F.relu(self.conv2(x))  # Apply second convolution and ReLU, Output size: 14x14, 64 channels\n",
    "        x = F.max_pool2d(x, 2)  # Max pooling, Output size: 7x7 (max pooling with kernel size 2 reduces dimensions by half)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for each image to 1D tensor (7x7x64 = 3136)\n",
    "        x = F.relu(self.fc1(x))  # Fully connected layer, Input size: 3136, Output size: 128\n",
    "        x = self.fc2(x)  # Output layer, Input size: 128, Output size: 10 (10 classes)\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef72a0844d23519e",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "We'll now define the training loop to optimize our model using the cross-entropy loss function and the Adam optimizer.\n",
    "\n",
    "### Exercise\n",
    "1. Define a function to train the model for a specified number of epochs.\n",
    "2. Print the training loss after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e9b2d2d4323664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:47:15.072326Z",
     "start_time": "2024-11-06T21:46:30.291872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1458, Accuracy: 95.61%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     18\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     20\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move to GPU\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asus\\miniconda3\\envs\\Deep-Learning\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    920\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, criterion, optimizer, epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move to GPU\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Optimize weights\n",
    "            \n",
    "            running_loss += loss.item()  # Accumulate loss\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get predicted classes\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "        \n",
    "        # Calculate average loss and accuracy\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffdb68841ef1798",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "After training, we need to evaluate our model on the test dataset to understand its performance.\n",
    "\n",
    "### Exercise\n",
    "1. Define a function to evaluate the model's accuracy on the test set.\n",
    "2. Print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753013a29969972c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:47:16.364925Z",
     "start_time": "2024-11-06T21:47:15.090847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 99.01%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No gradients needed for evaluation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)  # Forward pass\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get predicted classes\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "            \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test set: {accuracy:.2f}%')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e3a9ed9ac1b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:47:16.382072Z",
     "start_time": "2024-11-06T21:47:16.380630Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
