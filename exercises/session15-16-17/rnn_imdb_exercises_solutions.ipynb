{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RNNs Tutorial with PyTorch on the IMDB Dataset\n",
    "\n",
    "In this tutorial, we will build a Recurrent Neural Network (CNN) to classify movie reviews as positive or negative using the IMDB dataset.\n",
    " \n",
    "We'll go through the following steps:\n",
    "\n",
    "1. **Data Loading, Processing, and Augmentation**\n",
    "2. **Data Exploration**\n",
    "3. **Model Building**\n",
    "4. **Model Training**\n",
    "5. **Model Evaluation**\n",
    "\n"
   ],
   "id": "9cf2cd67a7fb4ec1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Data Loading, Processing, and Augmentation\n",
    "\n",
    "The IMDB dataset contains 50,000 movie reviews, split into 25,000 reviews for training and 25,000 reviews for testing. The dataset is preprocessed, and each review is encoded as a sequence of word indexes.\n",
    "\n",
    "### Exercise 1.1 - Data Loading and Processing\n",
    "\n",
    "1. Load the data from `'../../data/imdb_dataset.zip'` using pandas.\n",
    "2. Convert the `sentiment` column to a binary label (0 for negative and 1 for positive).\n",
    "3. Split the dataset into training and test sets (25,000 samples each).\n",
    "4. Preprocess the `review` column by converting it to lowercase and removing special characters, punctuation and stopwords. Additionally, use a stemming or lemmatization technique.\n",
    "5. Build a vocabulary of unique words in the training dataset.\n",
    "6. Tokenize the reviews using the vocabulary, i.e., replace each word with its index in the vocabulary. Note that the reviews should be padded to a fixed length.\n",
    "7. Create the data loaders for training and test datasets.\n"
   ],
   "id": "de854ac82e9a020b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:06:18.405307Z",
     "start_time": "2024-11-15T11:06:17.532548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../../data/imdb_dataset.zip', compression='zip')  # Load as per your format\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "df.head()"
   ],
   "id": "d98248f80f8d704a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:06:19.358189Z",
     "start_time": "2024-11-15T11:06:18.440889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.5, random_state=42)\n",
    "train_df.shape, test_df.shape"
   ],
   "id": "4d35a16ffac61778",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 2), (25000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:21.677479Z",
     "start_time": "2024-11-15T11:06:19.406533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters, including numbers\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    # stemming\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "train_df['preproc_review'] = train_df['review'].apply(preprocess_text)\n",
    "test_df['preproc_review'] = test_df['review'].apply(preprocess_text)"
   ],
   "id": "b973103232079f75",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:36.520044Z",
     "start_time": "2024-11-15T11:07:21.686679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# build vocabulary\n",
    "def tokenize_text(text):\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "train_df['tokens'] = train_df['preproc_review'].apply(tokenize_text)\n",
    "test_df['tokens'] = test_df['preproc_review'].apply(tokenize_text)\n",
    "\n",
    "all_tokens = set([word for tokens in train_df['tokens'] for word in tokens])\n",
    "# get top 5000 words\n",
    "top_5000 = pd.Series([word for tokens in train_df['tokens'] for word in tokens]).value_counts().index[:5000]\n",
    "vocab = {word: i + 2 for i, word in enumerate(top_5000)}\n",
    "vocab['<unk>'] = 0\n",
    "vocab['<pad>'] = 1\n",
    "\n",
    "len(vocab)"
   ],
   "id": "2d5dc17df6189d98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:37.106870Z",
     "start_time": "2024-11-15T11:07:36.563353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize reviews\n",
    "def tokenize_review(tokens):\n",
    "    return [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "\n",
    "train_df['tokenized'] = train_df['tokens'].apply(tokenize_review)\n",
    "test_df['tokenized'] = test_df['tokens'].apply(tokenize_review)"
   ],
   "id": "ca686b162ef1e561",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:37.151078Z",
     "start_time": "2024-11-15T11:07:37.142987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df.head()"
   ],
   "id": "570e293bcd709a1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "25858  \"Congo\" is based on the best-selling novel by ...          0   \n",
       "10784  Wow, here it finally is; the action \"movie\" wi...          0   \n",
       "24807  'IdentityÂ– . . . . I am part of my surrounding...          1   \n",
       "49534  \"Sir\" John Gielgud must have become senile to ...          0   \n",
       "3345   Below average movie with poor music considerin...          0   \n",
       "\n",
       "                                          preproc_review  \\\n",
       "25858  congo base best sell novel michael crichton th...   \n",
       "10784  wow final action movi without action real low ...   \n",
       "24807  ident part surround becam separ abl make diffe...   \n",
       "49534  sir john gielgud must becom senil star mess mo...   \n",
       "3345   averag movi poor music consid movi base music ...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "25858  [congo, base, best, sell, novel, michael, cric...   \n",
       "10784  [wow, final, action, movi, without, action, re...   \n",
       "24807  [ident, part, surround, becam, separ, abl, mak...   \n",
       "49534  [sir, john, gielgud, must, becom, senil, star,...   \n",
       "3345   [averag, movi, poor, music, consid, movi, base...   \n",
       "\n",
       "                                               tokenized  \n",
       "25858  [0, 323, 52, 1133, 507, 423, 0, 95, 302, 0, 28...  \n",
       "10784  [1132, 141, 110, 3, 131, 110, 72, 295, 256, 87...  \n",
       "24807  [1366, 67, 1235, 857, 1630, 432, 8, 0, 664, 16...  \n",
       "49534  [2150, 253, 0, 129, 142, 0, 82, 730, 3, 6, 5, ...  \n",
       "3345   [795, 3, 271, 81, 358, 3, 323, 81, 1662, 124, ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preproc_review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25858</th>\n",
       "      <td>\"Congo\" is based on the best-selling novel by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congo base best sell novel michael crichton th...</td>\n",
       "      <td>[congo, base, best, sell, novel, michael, cric...</td>\n",
       "      <td>[0, 323, 52, 1133, 507, 423, 0, 95, 302, 0, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>Wow, here it finally is; the action \"movie\" wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>wow final action movi without action real low ...</td>\n",
       "      <td>[wow, final, action, movi, without, action, re...</td>\n",
       "      <td>[1132, 141, 110, 3, 131, 110, 72, 295, 256, 87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24807</th>\n",
       "      <td>'IdentityÂ– . . . . I am part of my surrounding...</td>\n",
       "      <td>1</td>\n",
       "      <td>ident part surround becam separ abl make diffe...</td>\n",
       "      <td>[ident, part, surround, becam, separ, abl, mak...</td>\n",
       "      <td>[1366, 67, 1235, 857, 1630, 432, 8, 0, 664, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49534</th>\n",
       "      <td>\"Sir\" John Gielgud must have become senile to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir john gielgud must becom senil star mess mo...</td>\n",
       "      <td>[sir, john, gielgud, must, becom, senil, star,...</td>\n",
       "      <td>[2150, 253, 0, 129, 142, 0, 82, 730, 3, 6, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>Below average movie with poor music considerin...</td>\n",
       "      <td>0</td>\n",
       "      <td>averag movi poor music consid movi base music ...</td>\n",
       "      <td>[averag, movi, poor, music, consid, movi, base...</td>\n",
       "      <td>[795, 3, 271, 81, 358, 3, 323, 81, 1662, 124, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:37.647374Z",
     "start_time": "2024-11-15T11:07:37.228520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "def pad_or_truncate(indices, max_length=MAX_LENGTH):\n",
    "    if len(indices) > max_length:\n",
    "        return indices[:max_length]  # Truncate if longer than max_length\n",
    "    else:\n",
    "        return indices + [1] * (max_length - len(indices))  # Pad if shorter\n",
    "\n",
    "train_df['padded_tokenized'] = train_df['tokenized'].apply(lambda x: pad_or_truncate(x, MAX_LENGTH))\n",
    "test_df['padded_tokenized'] = test_df['tokenized'].apply(lambda x: pad_or_truncate(x, MAX_LENGTH))"
   ],
   "id": "116fc3f49260ae1c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:39.133639Z",
     "start_time": "2024-11-15T11:07:37.686058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the data to tensors\n",
    "def prepare_data(df):\n",
    "    inputs = torch.tensor(df['padded_tokenized'].tolist())\n",
    "    labels = torch.tensor(df['sentiment'].tolist())\n",
    "    return TensorDataset(inputs, labels)\n",
    "\n",
    "train_data = prepare_data(train_df)\n",
    "test_data = prepare_data(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ],
   "id": "560106d252698ec9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 1.2 - Data Augmentation\n",
    "\n",
    "1. Define a function to replace random words with synonyms from WordNet in the reviews.\n",
    "2. Augment the training dataset by replacing words in a few reviews with synonyms.\n",
    "\n",
    "Note: Never augment the test dataset. It's essential to evaluate the model on the original data."
   ],
   "id": "7a2ad79060d1313f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:41.850663Z",
     "start_time": "2024-11-15T11:07:39.143032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def augment_text(text, max_augment=3):\n",
    "    tokens = text.split()[:20]\n",
    "    augmented_tokens = tokens.copy()\n",
    "    \n",
    "    for _ in range(max_augment):\n",
    "        if len(augmented_tokens) > 1:\n",
    "            rand_idx = random.randint(0, len(augmented_tokens) - 1)\n",
    "            word = augmented_tokens[rand_idx]\n",
    "            synonyms = wordnet.synsets(word)\n",
    "            if synonyms:\n",
    "                replacement = random.choice(synonyms).lemmas()[0].name()\n",
    "                augmented_tokens[rand_idx] = replacement\n",
    "    print(f\"Original: {' '.join(tokens)}\")\n",
    "    print(f\"Augmented: {' '.join(augmented_tokens)}\")\n",
    "    print('\\n\\n')\n",
    "    return ' '.join(augmented_tokens)\n",
    "\n",
    "# Apply augmentation to training set\n",
    "train_df['review'].iloc[:3].apply(lambda x: augment_text(x, max_augment=3))"
   ],
   "id": "cec1e57df2661d62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \"Congo\" is based on the best-selling novel by Michael Crichton, which I thought lacked Crichton's usual charm, smart characters and\n",
      "Augmented: \"Congo\" is based on the best-selling novel by Michael Crichton, which one thought miss Crichton's usual charm, smart characters and\n",
      "\n",
      "\n",
      "\n",
      "Original: Wow, here it finally is; the action \"movie\" without action. In a real low-budget setting (don't miss the hilarious flying\n",
      "Augmented: Wow, here it finally is; the action \"movie\" without action. inch a real low-budget setting (don't miss the hilarious flying\n",
      "\n",
      "\n",
      "\n",
      "Original: 'IdentityÂ– . . . . I am part of my surroundings and I became separate from them and it's being\n",
      "Augmented: 'IdentityÂ– . . . . I am part of my surroundings and I became separate from them and it's being\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25858    \"Congo\" is based on the best-selling novel by ...\n",
       "10784    Wow, here it finally is; the action \"movie\" wi...\n",
       "24807    'IdentityÂ– . . . . I am part of my surrounding...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data Exploration\n",
    "\n",
    "Before training our model, it's essential to explore the data. This helps us understand its distribution and visualize some examples.\n",
    "\n",
    "### Exercise 2 - Data Exploration\n",
    "1. Print the number of positive and negative reviews in the training and test datasets.\n",
    "2. Plot a histogram of the length of reviews in the training and test datasets.\n",
    "3. Print a few reviews and their corresponding sentiment labels."
   ],
   "id": "8c4d4b41cceb7666"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:41.921298Z",
     "start_time": "2024-11-15T11:07:41.912045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# number of positive and negative reviews\n",
    "train_df['sentiment'].value_counts(), test_df['sentiment'].value_counts()"
   ],
   "id": "3d3e17130dd15243",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentiment\n",
       " 0    12517\n",
       " 1    12483\n",
       " Name: count, dtype: int64,\n",
       " sentiment\n",
       " 1    12517\n",
       " 0    12483\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:42.297614Z",
     "start_time": "2024-11-15T11:07:41.944059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# length of reviews (histogram)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sizes = train_df['tokenized'].apply(len)\n",
    "plt.hist(sizes, bins=30)"
   ],
   "id": "757af2ea7a33129d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.0260e+03, 1.0931e+04, 4.7480e+03, 2.4410e+03, 1.3860e+03,\n",
       "        9.0700e+02, 5.3200e+02, 3.6400e+02, 2.6400e+02, 1.7100e+02,\n",
       "        1.2300e+02, 6.9000e+01, 1.7000e+01, 6.0000e+00, 3.0000e+00,\n",
       "        3.0000e+00, 1.0000e+00, 3.0000e+00, 1.0000e+00, 2.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([   4.        ,   52.36666667,  100.73333333,  149.1       ,\n",
       "         197.46666667,  245.83333333,  294.2       ,  342.56666667,\n",
       "         390.93333333,  439.3       ,  487.66666667,  536.03333333,\n",
       "         584.4       ,  632.76666667,  681.13333333,  729.5       ,\n",
       "         777.86666667,  826.23333333,  874.6       ,  922.96666667,\n",
       "         971.33333333, 1019.7       , 1068.06666667, 1116.43333333,\n",
       "        1164.8       , 1213.16666667, 1261.53333333, 1309.9       ,\n",
       "        1358.26666667, 1406.63333333, 1455.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:42.420818Z",
     "start_time": "2024-11-15T11:07:42.324530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sizes = test_df['tokenized'].apply(len)\n",
    "plt.hist(sizes, bins=30)"
   ],
   "id": "ba41e3c8301a24c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.124e+03, 8.784e+03, 5.773e+03, 2.861e+03, 1.838e+03, 1.132e+03,\n",
       "        7.550e+02, 5.450e+02, 3.500e+02, 2.590e+02, 1.810e+02, 1.680e+02,\n",
       "        1.160e+02, 6.900e+01, 3.300e+01, 7.000e+00, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00]),\n",
       " array([   3. ,   43.4,   83.8,  124.2,  164.6,  205. ,  245.4,  285.8,\n",
       "         326.2,  366.6,  407. ,  447.4,  487.8,  528.2,  568.6,  609. ,\n",
       "         649.4,  689.8,  730.2,  770.6,  811. ,  851.4,  891.8,  932.2,\n",
       "         972.6, 1013. , 1053.4, 1093.8, 1134.2, 1174.6, 1215. ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:42.470805Z",
     "start_time": "2024-11-15T11:07:42.467747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print reviews and sentiment labels\n",
    "for i in range(5):\n",
    "    print(f\"Review: {train_df['review'].iloc[i]}\\nSentiment: {train_df['sentiment'].iloc[i]}\\n\")"
   ],
   "id": "c6b4941645567b17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \"Congo\" is based on the best-selling novel by Michael Crichton, which I thought lacked Crichton's usual charm, smart characters and punch. Well, sorry to say, but the same goes for the film.<br /><br />Here's the plot:<br /><br />Greed is bad, this simple morality tale cautions. A megalomaniacal C.E.O. (Joe Don Baker) sends his son into the dangerous African Congo on a quest for a source of diamonds large enough and pure enough to function as powerful laser communications transmitter (or is it laser weapons?). When contact is lost with his son and the team, his daughter-in-law (Laura Linney), a former CIA operative and computer-freak, is sent after them. On her quest, she is accompanied by gee-whiz gadgetry and a few eccentric characters (including a mercenary (Ernie Hudson), a researcher with a talking gorilla (Dylan Walsh), and a a nutty Indiana-Jones-type looking for King Solomon's Mines (Tim Curry). After some narrow escapes from surface-to-air missiles and some African wildlife, they all discover that often what we most want turns out to be the source of our downfall.<br /><br /> The actors in this movie were not talented. Dylan Walsh acts like a pathetic crybaby, especially at the end; Ernie Hudson is unconvincing (is it no wonder he went on to star in TV films?) and Laura Linney is nothing special. I think I can safely say the only talented actors in this film had very small roles: Joe Don Baker and Tim Curry, an always enjoyable actor (although sometimes scarred for life by constantly being reminded of his \"Rocky Horror Picture\" days).<br /><br /> This movie also had some other problems, including awful direction style, cheesy dialogue and a just-plain-boring plot, which was completely hashed when compared to Crichton's novel.<br /><br /> Not even Stan Winston's creature effects could save this movie from being a disaster. I am deeply disappointed in this movie; there was not even a campy quality to redeem itself with. It was just plain awful, cheesy, boring and ridiculous, and proves to be one of the worst Crichton book-to-film productions.<br /><br />2/5 stars -<br /><br />John Ulmer\n",
      "Sentiment: 0\n",
      "\n",
      "Review: Wow, here it finally is; the action \"movie\" without action. In a real low-budget setting (don't miss the hilarious flying saucers flying by a few times) of a future Seattle we find a no-brain hardbody seeking to avenge her childhood.<br /><br />There is nothing even remotely original or interesting about the plot and the actors' performance is only rivalled in stupidity by the attempts to steal from other movies, mainly \"Matrix\" without having the money to do it right. Yes, we do get to see some running on walls and slow motion shoot-outs (45 secs approx.) but these scenes are about as cool as the stupid hardbody's attempts at making jokes about male incompetence now and then.<br /><br />And, yes, we are also served a number of leads that lead absolutely nowhere, as if the script was thought-out by the previously unseen cast while shooting the scenes.<br /><br />Believe me, it is as bad as it possibly can get. In fact, it doesn't deserve to be taken seriously, but perhaps I can make some of you not rent it and save your money.\n",
      "Sentiment: 0\n",
      "\n",
      "Review: 'IdentityÂ– . . . . I am part of my surroundings and I became separate from them and it's being able to make those differentiations clearly that lets us have an identity and what's inside our identity is everything that's ever happened to us' (Ntozake Shange qtd in \"Fires in the Mirror\").<br /><br />Pieces like Decalogue V used to intimidate me. I felt that if I accepted them, than I would be compromising something. What I thought before really isn't worth getting into. I understand what Naturalism is trying to say. I experienced a tangible katharsis, and one that fell into existence piecemeal, and one that's still alive, that I still have to reckon with. It's still working inside me. <br /><br />The film wasn't sympathetic, per se. It doesn't need to say that the death penalty is a wicked thing. There are certainly wicked people; whether or not they should die is for another film. What Decalogue shows is that good, beautiful people exists who kill other people when their society and primal urges jack them up. <br /><br />The 'science' of naturalism is what has helped me to appreciate Decalogue V. It's not worth the writing space to go into why I would not let myself before, but I see now the worth in making art like this to 'make' people, or perhaps to make people do something. <br /><br />There's a method to Lazar's compromise of his . . . light. Much of that meaning makes sense only in retrospect. This should not be too strange of an idea: after all, how much of respectable science does not gain meaning in retrospect. I wince when I say it, but Naturalism seems so much more productive and so much less nihilistic when I have the power to say to myself, 'this ruin, this process, this natural process, makes me want to buck the system.' <br /><br />I do not think Naturalism is painting a doomsday portrait of humanity, telling us to give up our powdered wigs and head to the woods. Instead, I think that it is cataloging proofs and experiments, that we are, of course, free to ignore. We can ignore it all we want, if we want to give the Naturalists more corpses to bury. <br /><br />For surely, despite their aesthetic specifically designed without sympathy towards their characters' likely and catastrophic fate, they are impassioned by readerly inaction and writerly snobisme. I do see the delightful risk in the hope that the audience will understand what's to be done with what they see. As has been mentioned, there's danger in the hopeless seeing their fate immortalized in stone. There's danger in the hopeful disparaging the Natural because it doesn't correspond to their world view.<br /><br />And I don't think that the 'hopeful' need be either wealthy or fortunate. I have not seen it, but it seems that the film American Beauty proves the inadequacy of circumstance as a provider of vision or comfort. There are ascetics as well as gluttons as well as beggars who wonder where within themselves their humanity is, who grieve because they can't find anything that separates them from their landscape. <br /><br />Landscapes can be powerfully and beautifully portrayed, but in reality, landscapes do not enact. They change, sure, and dramatically, but only by a large set of Natural law which no one truly have power over. But it cannot be changed itself.\n",
      "Sentiment: 1\n",
      "\n",
      "Review: \"Sir\" John Gielgud must have become senile to star in a mess of a movie like this one.;<br /><br />This is one of those films, I suppose, that is considered \"art,\" but don't be fooled.....it's garbage. Stick to the \"art\" you can admire in a frame because the films that are labeled as such are usually unintelligible forgeries like this.<br /><br />In this masterpiece, Giegud recites Shakespeare's \"The Tempest\" while the camera pans away to nude people. one of them a little kid urinating in a swimming pool. Wow, this is heady stuff and real \"art,\" ain't it?? That's just one example. Most of the story makes no sense, is impossible to follow and, hence, is one that Liberal critics are afraid to say they didn't \"understand\" so they give it high marks to save their phony egos. You want Shakespeare? Read his books.\n",
      "Sentiment: 0\n",
      "\n",
      "Review: Below average movie with poor music considering a movie based on music??? Ordinary Script & Direction with full of blunders. Salman Khan was at his usual acting. Ajay's performance deteriorating with time as his looks,especially his styles as a Rock Star were pathetic. Asin was just a showpiece only. Overall I felt like wasting my money in cinema. Salman Khan remains as immature as 10 years ago compared to Aamir Khan. There were many songs in the movie all boring except \"Man Ko Ati\". The Most Important Song to impress the UK Music Sponsor was most unimpressive. \"Khanabadosh\" can be very easily understood by an English Music Sponsor. The other movie I saw last week was \"Wake Up Sid\" which was simple slow love story with good direction & acting despite average music\n",
      "Sentiment: 0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Model Building\n",
    "\n",
    "Now, we'll define our RNN architecture. A typical RNN consists of an embedding layer, RNN layers, and a fully connected layers.\n",
    "\n",
    "### Exercise\n",
    "1. Define a RNN class inheriting from torch.nn.Module.\n",
    "2. Include one Embedding layer, two LSTM layers, and two Linear layers."
   ],
   "id": "ebf01dbc897fa0e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:42.537023Z",
     "start_time": "2024-11-15T11:07:42.520010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.rnn2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, int(hidden_size/2))\n",
    "        self.fc2 = nn.Linear(int(hidden_size/2), output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.rnn(x) # output, (h_n, c_n). h_n is the hidden state of the layer, c_n is the cell state of the layer\n",
    "        x, (hn, cn) = self.rnn2(x)\n",
    "        x = F.relu(self.fc(hn[-1]))\n",
    "        x = self.fc2(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# Model initialization\n",
    "model = RNNModel(vocab_size=len(vocab), embed_size=128, hidden_size=64, output_size=1)\n",
    "model"
   ],
   "id": "86bc9381447392ae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (embedding): Embedding(5002, 128)\n",
       "  (rnn): LSTM(128, 64, batch_first=True)\n",
       "  (rnn2): LSTM(64, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Model Training\n",
    "\n",
    "We'll now define the training loop to optimize our model using the binary cross-entropy loss function and the Adam optimizer.\n",
    "\n",
    "### Exercise\n",
    "1. Define a function to train the model for a specified number of epochs.\n",
    "2. Print the training loss after each epoch."
   ],
   "id": "ef72a0844d23519e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:42.863496Z",
     "start_time": "2024-11-15T11:07:42.574710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = loss_fn(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predictions = (outputs.squeeze() > 0.5).long()\n",
    "        correct_preds += (predictions == labels).sum().item()\n",
    "        total_preds += len(labels)\n",
    "\n",
    "    accuracy = correct_preds / total_preds\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy*100:.2f}%\")"
   ],
   "id": "60e9b2d2d4323664",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n\u001B[1;32m      4\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Hyperparameters\u001B[39;00m\n\u001B[1;32m      9\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1171\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m-> 1174\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    778\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    779\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 780\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    782\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    785\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    790\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    791\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    801\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 805\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    806\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    808\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1153\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1154\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[1;32m   1155\u001B[0m             device,\n\u001B[1;32m   1156\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m             non_blocking,\n\u001B[1;32m   1158\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[1;32m   1159\u001B[0m         )\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1163\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:42.868065102Z",
     "start_time": "2024-11-07T00:19:14.323327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(texts)"
   ],
   "id": "2b113a98eea5dfbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[43593, 58655, 67253,  ..., 74555, 35961, 57393],\n",
      "        [ 2166,  8269, 19154,  ...,     1,     1,     1],\n",
      "        [17991, 52254, 59359,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [46424, 24314, 73279,  ...,     1,     1,     1],\n",
      "        [36647, 42199,  1048,  ...,     1,     1,     1],\n",
      "        [10860, 11215, 25506,  ...,     1,     1,     1]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "After training, we need to evaluate our model on the test dataset to understand its performance.\n",
    "\n",
    "### Exercise\n",
    "1. Define a function to evaluate the model's accuracy on the test set.\n",
    "2. Print the accuracy."
   ],
   "id": "5ffdb68841ef1798"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:42.874021269Z",
     "start_time": "2024-11-07T00:16:23.436140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "correct_preds = 0\n",
    "total_preds = 0\n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        predictions = (outputs.squeeze() > 0).long()\n",
    "        correct_preds += (predictions == labels).sum().item()\n",
    "        total_preds += len(labels)\n",
    "\n",
    "accuracy = correct_preds / total_preds\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ],
   "id": "753013a29969972c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 50.07%\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T11:07:42.874489367Z",
     "start_time": "2024-11-06T23:18:07.817178Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "f97e3a9ed9ac1b32",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
